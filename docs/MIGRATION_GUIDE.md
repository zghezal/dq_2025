# üîÑ Guide de Migration - Sources de Donn√©es Multiples

## Pour les Utilisateurs Existants

Si vous avez d√©j√† des canaux configur√©s, voici comment migrer vers le nouveau syst√®me multi-sources.

---

## Changements

### Avant (Syst√®me Ancien)

```python
FileSpecification(
    file_id='sales',
    name='Fichier des ventes',
    format=FileFormat.CSV
)
# ‚û°Ô∏è Upload manuel uniquement via l'interface
```

### Apr√®s (Syst√®me Nouveau)

```python
FileSpecification(
    file_id='sales',
    name='Fichier des ventes',
    format=FileFormat.CSV,
    source_type=DataSourceType.LOCAL,  # ‚úÖ Explicite
    connection_params={}                # ‚úÖ Vide pour upload manuel
)
```

---

## R√©trocompatibilit√©

‚úÖ **Tous les canaux existants continuent de fonctionner** sans modification !

Le champ `source_type` a une valeur par d√©faut :

```python
source_type: DataSourceType = DataSourceType.LOCAL  # Par d√©faut
```

Les anciens canaux seront automatiquement trait√©s comme des uploads locaux.

---

## Migration Manuelle (Optionnel)

### √âtape 1 : Identifier les Canaux

```python
from src.core.channel_manager import ChannelManager

manager = ChannelManager()
channels = manager.list_channels()

for channel in channels:
    print(f"Canal: {channel.name}")
    for spec in channel.file_specifications:
        print(f"  - {spec.name}: {spec.source_type}")
```

### √âtape 2 : Mettre √† Jour un Canal

#### Exemple : Passer d'Upload Local √† SharePoint

```python
# Charger le canal existant
channel = manager.get_channel('my_channel_id')

# Trouver la spec √† modifier
spec = next(s for s in channel.file_specifications if s.file_id == 'sales')

# Changer pour SharePoint
spec.source_type = DataSourceType.SHAREPOINT
spec.connection_params = {
    'site_url': 'https://company.sharepoint.com/sites/data',
    'folder_path': '/Shared Documents/Sales',
    'file_name': 'sales_monthly.xlsx',
    'access_token': os.environ['SP_TOKEN'],
    'format': 'xlsx'
}

# Sauvegarder
manager.update_channel(channel)
```

#### Exemple : Ajouter une Source Dataiku en Compl√©ment

```python
# Ajouter une nouvelle spec Dataiku
from src.core.models_channels import FileSpecification, DataSourceType, FileFormat

new_spec = FileSpecification(
    file_id='history_dku',
    name='Historique (Dataiku)',
    source_type=DataSourceType.DATAIKU_DATASET,
    format=FileFormat.CSV,
    required=False,
    connection_params={
        'project_key': 'SALES',
        'dataset_name': 'sales_history',
        'sampling': 'head',
        'limit': 50000
    }
)

channel.file_specifications.append(new_spec)
manager.update_channel(channel)
```

---

## Sc√©narios de Migration Courants

### Sc√©nario 1 : Automatiser avec HUE

**Avant** : L'√©quipe uploadait manuellement un fichier extrait depuis Hive.

**Apr√®s** : Configuration directe vers HUE.

```python
spec.source_type = DataSourceType.HUE
spec.connection_params = {
    'hue_url': 'http://hue.company.com:8888',
    'auth_token': os.environ['HUE_TOKEN'],
    'query': 'SELECT * FROM sales WHERE date >= current_date - 30',
    'database': 'production'
}
```

**Avantage** : Donn√©es toujours √† jour, pas besoin d'extraction manuelle.

---

### Sc√©nario 2 : Centraliser sur SharePoint

**Avant** : Chaque √©quipe uploadait via l'interface web.

**Apr√®s** : Les √©quipes d√©posent sur SharePoint, le syst√®me r√©cup√®re automatiquement.

```python
spec.source_type = DataSourceType.SHAREPOINT
spec.connection_params = {
    'site_url': 'https://company.sharepoint.com/sites/dq',
    'folder_path': '/Shared Documents/TeamA/Deposits',
    'file_name': 'data_monthly.xlsx',
    'client_id': os.environ['SP_CLIENT_ID'],
    'client_secret': os.environ['SP_CLIENT_SECRET'],
    'format': 'xlsx'
}
```

**Avantage** : Les √©quipes utilisent SharePoint (d√©j√† connu), le DQ est automatique.

---

### Sc√©nario 3 : R√©utiliser des Datasets Dataiku

**Avant** : Export manuel depuis Dataiku ‚Üí Upload sur DQ.

**Apr√®s** : R√©f√©rence directe au dataset.

```python
spec.source_type = DataSourceType.DATAIKU_DATASET
spec.connection_params = {
    'project_key': 'PREP_SALES',
    'dataset_name': 'sales_prepared',
    'sampling': 'full'
}
```

**Avantage** : Pas d'export/import, donn√©es synchronis√©es.

---

## Script de Migration Complet

```python
"""
Migration des canaux vers sources multiples
Convertit les uploads locaux en sources SharePoint/HUE/Dataiku
"""

import os
from src.core.channel_manager import ChannelManager
from src.core.models_channels import DataSourceType

# Configuration de migration
MIGRATIONS = {
    'sales_channel': {
        'file_id': 'sales',
        'new_source': DataSourceType.SHAREPOINT,
        'params': {
            'site_url': 'https://company.sharepoint.com/sites/sales',
            'folder_path': '/Shared Documents/DQ',
            'file_name': 'sales_latest.xlsx',
            'access_token': os.environ['SP_TOKEN'],
            'format': 'xlsx'
        }
    },
    'inventory_channel': {
        'file_id': 'inventory',
        'new_source': DataSourceType.DATAIKU_DATASET,
        'params': {
            'project_key': 'INVENTORY',
            'dataset_name': 'inventory_master',
            'sampling': 'full'
        }
    }
}

def migrate_channels():
    manager = ChannelManager()
    
    for channel_id, config in MIGRATIONS.items():
        print(f"\nüîÑ Migration du canal: {channel_id}")
        
        # Charger le canal
        channel = manager.get_channel(channel_id)
        if not channel:
            print(f"  ‚ùå Canal introuvable: {channel_id}")
            continue
        
        # Trouver la spec √† migrer
        spec = next((s for s in channel.file_specifications 
                    if s.file_id == config['file_id']), None)
        
        if not spec:
            print(f"  ‚ùå FileSpec introuvable: {config['file_id']}")
            continue
        
        # Backup de l'ancienne config
        print(f"  üìã Ancien: {spec.source_type.value}")
        
        # Appliquer la migration
        spec.source_type = config['new_source']
        spec.connection_params = config['params']
        
        print(f"  ‚úÖ Nouveau: {spec.source_type.value}")
        
        # Sauvegarder
        manager.update_channel(channel)
        print(f"  üíæ Canal sauvegard√©")
    
    print("\n‚úÖ Migration termin√©e !")

if __name__ == '__main__':
    migrate_channels()
```

---

## V√©rification Post-Migration

### Test de Connexion

```python
from src.connectors.factory import ConnectorFactory

# Pour chaque spec migr√©e
spec = channel.file_specifications[0]

connector = ConnectorFactory.create_connector(
    spec.source_type,
    spec.connection_params
)

success, message = connector.test_connection()
if success:
    print(f"‚úÖ {spec.name}: {message}")
else:
    print(f"‚ùå {spec.name}: {message}")
```

### Test de Chargement

```python
# Charger un √©chantillon
df = connector.fetch_data()
print(f"‚úÖ {len(df)} lignes charg√©es")
print(f"Colonnes: {list(df.columns)}")
```

---

## Rollback (Retour Arri√®re)

Si besoin de revenir √† l'ancien syst√®me :

```python
# Revenir √† LOCAL
spec.source_type = DataSourceType.LOCAL
spec.connection_params = {}

manager.update_channel(channel)
```

**Note** : Les fichiers upload√©s manuellement avant la migration sont toujours disponibles.

---

## Support

Pour toute question sur la migration :

1. Consulter `DATA_SOURCES_DOC.md` pour la doc compl√®te
2. Ex√©cuter `demo_data_sources.py` pour tester les connecteurs
3. Contacter l'√©quipe DQ pour assistance

---

**Date de Migration** : 2025-11-08  
**Version** : 1.0
